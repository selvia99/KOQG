{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mollusca adalah hewan yang bersifat tripoblastik slomata\n",
    "ulat mengalami perubahan bentuk\n",
    "ulat berubah menjadi kepompong\n",
    "kepompong berubah menjadi kupu-kupu\n",
    "kelenjar sutra digunakan membuat kepompong\n",
    "kupu-kupu mengalami metamorfosis sempurna karena mengalami perubahan bentuk\n",
    "organisasi pergerakan mendorong keinginan untuk bekerja sama\n",
    "masa praaksara adalah masa ketika manusia belum mengenal tulisan\n",
    "tokoh organisasi berjuang bersama untuk mencapai kemerdekaan\n",
    "ras melanesoid merupakan ras yang datang  ke kepulauan indonesia setelah proto melayu datang\n",
    "Indonesia dijajah oleh Belanda\n",
    "\n",
    "\n",
    "mollusca adalah hewan yang bertubuh lunak\n",
    "Hewan > Reptil : kadal - ular - buaya"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from numpy import asarray\n",
    "from numpy import savetxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NNP mollusca))\n",
      "  (PRE (VB adalah))\n",
      "  (OBJ\n",
      "    (NN hewan)\n",
      "    (PEWATAS\n",
      "      (DT yang)\n",
      "      (VB bersifat)\n",
      "      (FNOM (NNP tripoblastik) (NNP slomata)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NN ulat))\n",
      "  (PRE (VB mengalami))\n",
      "  (OBJ (FNOM (NNP perubahan) (NN bentuk))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NN ulat))\n",
      "  (PRE (FVERB (VB berubah) (VB menjadi)))\n",
      "  (OBJ (NN kepompong)))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NN kepompong))\n",
      "  (PRE (FVERB (VB berubah) (VB menjadi)))\n",
      "  (OBJ (NN kupu-kupu)))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NNP kelenjar) (NN sutra)))\n",
      "  (PRE (FVERB (VB digunakan) (VB membuat)))\n",
      "  (OBJ (NN kepompong)))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NN kupu-kupu))\n",
      "  (PRE (VB mengalami))\n",
      "  (OBJ (FADJE (NNP metamorfosis) (JJ sempurna)))\n",
      "  (KET\n",
      "    (FPREP\n",
      "      (FPREP (IN karena) (VB mengalami))\n",
      "      (FNOM (NNP perubahan) (NN bentuk)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NN kupu-kupu))\n",
      "  (PRE (VB mengalami))\n",
      "  (OBJ (FADJE (NNP metamorfosis) (JJ sempurna)))\n",
      "  (KET\n",
      "    (SC karena)\n",
      "    (KLAUSA\n",
      "      (PRE (VB mengalami))\n",
      "      (OBJ (FNOM (NNP perubahan) (NN bentuk))))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NNP organisasi) (NN pergerakan)))\n",
      "  (PRE (VB mendorong))\n",
      "  (OBJ (NN keinginan))\n",
      "  (KET (SC untuk) (KLAUSA (PRE (FVERB (VB bekerja) (JJ sama))))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NN masa) (NN praaksara)))\n",
      "  (PRE (VB adalah))\n",
      "  (OBJ (NN masa))\n",
      "  (KET\n",
      "    (SC ketika)\n",
      "    (KLAUSA\n",
      "      (SUB (NN manusia))\n",
      "      (PRE (FVERB (NEG belum) (VB mengenal)))\n",
      "      (OBJ (NN tulisan)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NN tokoh) (NNP organisasi)))\n",
      "  (PRE (FVERB (VB berjuang) (JJ bersama)))\n",
      "  (KET\n",
      "    (SC untuk)\n",
      "    (KLAUSA (PRE (VB mencapai)) (OBJ (NN kemerdekaan)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NN tokoh) (NNP organisasi)))\n",
      "  (PRE (FVERB (VB berjuang) (VB bersama)))\n",
      "  (KET\n",
      "    (SC untuk)\n",
      "    (KLAUSA (PRE (VB mencapai)) (OBJ (NN kemerdekaan)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NN ras) (NNP melanesoid)))\n",
      "  (PRE (VB merupakan))\n",
      "  (OBJ (NN ras) (PEWATAS (DT yang) (VB datang)))\n",
      "  (KET\n",
      "    (FPREP (IN ke) (FNOM (NN kepulauan) (NNP indonesia)))\n",
      "    (SC setelah)\n",
      "    (KLAUSA (SUB (FNOM (NNP proto) (NNP melayu))) (PRE (VB datang)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (FNOM (NN ras) (NNP melanesoid)))\n",
      "  (PRE (VB merupakan))\n",
      "  (OBJ\n",
      "    (NN ras)\n",
      "    (PEWATAS\n",
      "      (DT yang)\n",
      "      (VB datang)\n",
      "      (FPREP (IN ke) (FNOM (NN kepulauan) (NNP indonesia)))))\n",
      "  (KET\n",
      "    (SC setelah)\n",
      "    (KLAUSA (SUB (FNOM (NNP proto) (NNP melayu))) (PRE (VB datang)))))\n",
      "parsing grammar...\n",
      "(S\n",
      "  (SUB (NNP Indonesia))\n",
      "  (PRE (VB dijajah))\n",
      "  (KET (FPREP (IN oleh) (NNP Belanda))))\n"
     ]
    }
   ],
   "source": [
    "#MEMBUAT PARSE TREE\n",
    "\n",
    "arr = np.genfromtxt(\"K1.txt\", dtype=str, delimiter='##')\n",
    "grammar1 = nltk.data.load('file:Grammar(ind).cfg')\n",
    "parser = nltk.ChartParser(grammar1)\n",
    "final = ''\n",
    "\n",
    "for i in range(len(arr)):\n",
    "  x = arr[i].split()\n",
    "  x = np.array(x)\n",
    "  output = '' \n",
    "  for tree in parser.parse(x):\n",
    "      print(\"parsing grammar...\")\n",
    "      print(tree)\n",
    "      #output = output + str(tree)\n",
    "      #output = output.replace(\"\\n\", \"\")\n",
    "      #final = final + '\\n' + output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proses selesai\n"
     ]
    }
   ],
   "source": [
    "#Preproses untuk menghilangkan tanda () dll\n",
    "#K3 = K4.CSV\n",
    "import re\n",
    "\n",
    "inputs = open(r\"K2.txt\",\"r\").read()\n",
    "inputs = inputs.lower()\n",
    "inputs = inputs.split(\"\\n\")\n",
    "\n",
    "outputs1 = open(\"K3.txt\",\"w\")\n",
    "\n",
    "for i in inputs:\n",
    "    x = i.replace('\"', \" \")\n",
    "    a = x.replace(\"(\", \" \")\n",
    "    b = a.replace(\")\", \" \")\n",
    "    c = re.sub('\\s+',' ',b)\n",
    "    \n",
    "    if (c == ' s'):\n",
    "        outputs1.writelines('\\n')\n",
    "        outputs1.writelines (c)        \n",
    "    else:\n",
    "        outputs1.writelines (c)\n",
    " \n",
    "outputs1.close()\n",
    "print(\"proses selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PENOMORAN KOMPONEN PARSETREE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 395,
     "status": "ok",
     "timestamp": 1666250678260,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "vu_poxX3CaQF"
   },
   "outputs": [],
   "source": [
    "s_tree = ['sub', 'pre', 'obj', 'pel', 'ket', 's']\n",
    "cc_tree = ['cc']\n",
    "sc_tree = ['sc']\n",
    "klausa_tree = ['klausa']\n",
    "sub_tree = ['prp', 'nn', 'nnp', 'fnum', 's', 'nn', 'pewatas']\n",
    "pre_tree = ['vb', 'fverb', 'fnom', 'fprep', 'fadje']\n",
    "obj_tree = ['nn', 'nnp', 'fnom', 'sc', 's']\n",
    "pel_tree = ['nn', 'jj', 'fnom', 'fadje', 'in', 'nnp', 'kr', 'pre', 'fverb']\n",
    "ket_tree = ['fprep', 'fket', 'fnom', 'fverb', 'sc', 's']\n",
    "pewatas_tree = ['dt', 'fnom', 'dt', 'fverb']\n",
    "fnum_tree = ['cd', 'nnd', 'cd', 'nn', 'fnum', 'prp']\n",
    "fnom_tree = ['nn', 'nnp', 'pr', 'prp', 'jj', 'fnom']\n",
    "fverb_tree = ['sc', 'vb', 'md', 'rb', 'jj', 'nnp', 'cc']\n",
    "fadje_tree = ['jj', 'rb', 'nn', 'vb', 'neg']\n",
    "bfprep_tree = ['in', 'fprep', 'nn', 'nnp', 'cd', 'fnom', 'fverb', 'fnum', 'sc']\n",
    "fket_tree = ['ketn', 'pr']\n",
    "ketn_tree = ['kemarin', 'siang', 'siang', 'sore', 'pagi', 'malam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 533,
     "status": "ok",
     "timestamp": 1666250682030,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "yPiPJ_O5CbNO"
   },
   "outputs": [],
   "source": [
    "tree_dict = {\n",
    "    's': s_tree,\n",
    "    'klausa': klausa_tree,\n",
    "    'sub': sub_tree,\n",
    "    'pre': pre_tree,\n",
    "    'obj': obj_tree,\n",
    "    'pel': pel_tree,\n",
    "    'ket': ket_tree,\n",
    "    'cc': cc_tree,\n",
    "    'sc': sc_tree,\n",
    "    'pewatas': pewatas_tree,\n",
    "    'fnum': fnum_tree,\n",
    "    'fnom': fnom_tree,\n",
    "    'fverb': fverb_tree,\n",
    "    'fadje': fadje_tree,\n",
    "    'fprep': bfprep_tree,\n",
    "    'fket': fket_tree,\n",
    "    'ketn': ketn_tree\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1666250690712,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "C0ASs5qcCeQA"
   },
   "outputs": [],
   "source": [
    "#harus diset dulu jika ingin memasukkan nilai baru agar bersifat unik\n",
    "\n",
    "counter_tree = {\n",
    "    's': 0,\n",
    "    'klausa': 0,\n",
    "    'sub': 0,\n",
    "    'pre': 0,\n",
    "    'obj': 0,\n",
    "    'pel': 0,\n",
    "    'ket': 0,\n",
    "    'cc' : 0,\n",
    "    'sc' : 0,\n",
    "    'pewatas': 0,\n",
    "    'fnum': 0,\n",
    "    'fnom': 0,\n",
    "    'fverb': 0,\n",
    "    'fadje': 0,\n",
    "    'fprep': 0,\n",
    "    'fket': 0,\n",
    "    'ketn': 0\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 322,
     "status": "ok",
     "timestamp": 1666250710125,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "prZ4WeKeCh6x"
   },
   "outputs": [],
   "source": [
    "#remove ()dll\n",
    "def load_csv(file):\n",
    "  with open(file) as file_name:\n",
    "    file_read = csv.reader(file_name)\n",
    "    temp = list(file_read)\n",
    "    temp1 = [i[0] for i in temp]\n",
    "    final_list = []\n",
    "    for elem in temp1:\n",
    "      if '(' in elem:\n",
    "        elem = elem.replace('(', '')\n",
    "      if ')' in elem:\n",
    "        elem = elem.replace(')', '')\n",
    "      final_list.append(elem)\n",
    "    return final_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1666250711616,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "ME4UsOhoCi6w"
   },
   "outputs": [],
   "source": [
    "arr = load_csv('K4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1666250713973,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "oSKxxpcjCsht",
    "outputId": "55a7b9a9-46d5-4bdd-a60f-82960ce46c4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selesai\n"
     ]
    }
   ],
   "source": [
    "#menyimpan array asli\n",
    "arr_asli = []\n",
    "\n",
    "for i in arr:\n",
    "    arr_asli.append(i.split())\n",
    "\n",
    "# for a in arr_asli:\n",
    "#   print(a)\n",
    "print(\"selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 483,
     "status": "ok",
     "timestamp": 1666250732597,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "4cXpkV-CC3jl",
    "outputId": "b2aeb27b-ff6c-4041-a40c-4c66198cc901"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['s1', 'sub1', 'nnp', 'mollusca', 'pre1', 'vb', 'adalah', 'obj1', 'nn', 'hewan', 'pewatas1', 'dt', 'yang', 'vb', 'bersifat', 'fnom1', 'nnp', 'tripoblastik', 'nnp', 'slomata']\n",
      "['s2', 'sub2', 'nn', 'ulat', 'pre2', 'vb', 'mengalami', 'obj2', 'fnom2', 'nnp', 'perubahan', 'nn', 'bentuk']\n",
      "['s3', 'sub3', 'nn', 'ulat', 'pre3', 'fverb1', 'vb', 'berubah', 'vb', 'menjadi', 'obj3', 'nn', 'kepompong']\n",
      "['s4', 'sub4', 'nn', 'kepompong', 'pre4', 'fverb2', 'vb', 'berubah', 'vb', 'menjadi', 'obj4', 'nn', 'kupu-kupu']\n",
      "['s5', 'sub5', 'fnom3', 'nnp', 'kelenjar', 'nn', 'sutra', 'pre5', 'fverb3', 'vb', 'digunakan', 'vb', 'membuat', 'obj5', 'nn', 'kepompong']\n",
      "['s6', 'sub6', 'nn', 'kupu-kupu', 'pre6', 'vb', 'mengalami', 'obj6', 'fadje1', 'nnp', 'metamorfosis', 'jj', 'sempurna', 'ket1', 'fprep1', 'fprep2', 'in', 'karena', 'vb', 'mengalami', 'fnom4', 'nnp', 'perubahan', 'nn', 'bentuk']\n",
      "['s7', 'sub7', 'fnom5', 'nnp', 'organisasi', 'nn', 'pergerakan', 'pre7', 'vb', 'mendorong', 'obj7', 'nn', 'keinginan', 'ket2', 'sc1', 'untuk', 'klausa1', 'pre8', 'fverb4', 'vb', 'bekerja', 'jj', 'sama']\n",
      "['s8', 'sub8', 'fnom6', 'nn', 'masa', 'nn', 'praaksara', 'pre9', 'vb', 'adalah', 'obj8', 'nn', 'masa', 'ket3', 'sc2', 'ketika', 'klausa2', 'sub9', 'nn', 'manusia', 'pre10', 'fverb5', 'neg', 'belum', 'vb', 'mengenal', 'obj9', 'nn', 'tulisan']\n",
      "['s9', 'sub10', 'fnom7', 'nn', 'tokoh', 'nnp', 'organisasi', 'pre11', 'fverb6', 'vb', 'berjuang', 'jj', 'bersama', 'ket4', 'sc3', 'untuk', 'klausa3', 'pre12', 'vb', 'mencapai', 'obj10', 'nn', 'kemerdekaan']\n",
      "['s10', 'sub11', 'fnom8', 'nn', 'ras', 'nnp', 'melanesoid', 'pre13', 'vb', 'merupakan', 'obj11', 'nn', 'ras', 'pewatas2', 'dt', 'yang', 'vb', 'datang', 'fprep3', 'in', 'ke', 'fnom9', 'nn', 'kepulauan', 'nnp', 'indonesia', 'ket5', 'sc4', 'setelah', 'klausa4', 'sub12', 'fnom10', 'nnp', 'proto', 'nnp', 'melayu', 'pre14', 'vb', 'datang']\n",
      "['s11', 'sub13', 'nnp', 'indonesia', 'pre15', 'vb', 'dijajah', 'ket6', 'fprep4', 'in', 'oleh', 'nnp', 'belanda']\n",
      "selesai\n"
     ]
    }
   ],
   "source": [
    "#menyimpan array dengan number\n",
    "arr_gabungan = []\n",
    "for i in arr_asli:\n",
    "  temp = []\n",
    "  for j in range(len(i)):\n",
    "    if i[j] in tree_dict:\n",
    "      curr = i[j]\n",
    "      counter_tree[curr] += 1\n",
    "      temp.append(curr+str(counter_tree[curr]))\n",
    "    else:\n",
    "      temp.append(i[j])\n",
    "  arr_gabungan.append(temp)\n",
    "\n",
    "for a in arr_gabungan:\n",
    "  print(a)\n",
    "print(\"selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 616,
     "status": "ok",
     "timestamp": 1666250791346,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "2aFeC0wHDD-b"
   },
   "outputs": [],
   "source": [
    "#cari letak komponen tree\n",
    "\n",
    "cari = ['s','a_sub','b_pre','c_obj','d_pel','e_ket','cc','sc','fnom','fnum','fprep','fket','fverb','fadje','pewatas','konj','subord','klausa']\n",
    "def find(arr):\n",
    "  x = np.array(arr)\n",
    "  ls = np.where(x == 's')\n",
    "  lsub = np.where(x == 'a_sub')\n",
    "  lpre = np.where(x == 'b_pre')\n",
    "  lobj = np.where(x == 'c_obj')\n",
    "  lpel = np.where(x == 'd_pel')\n",
    "  lket = np.where(x == 'e_ket')\n",
    "  lcc = np.where(x == 'cc')\n",
    "  lsc = np.where(x == 'sc')\n",
    "  lfnom = np.where(x == 'fnom')\n",
    "  lfnum = np.where(x == 'fnum')\n",
    "  lfprep = np.where(x == 'fprep')\n",
    "  lfket = np.where(x == 'fket')\n",
    "  lfverb = np.where(x == 'fverb')\n",
    "  lfadje = np.where(x == 'fadje')\n",
    "  lpewatas = np.where(x == 'pewatas')\n",
    "  lkonj = np.where(x == 'konj')\n",
    "  lsubord = np.where(x == 'subord')\n",
    "  lklausa = np.where(x == 'klausa')\n",
    "\n",
    "  ls_ = ls[0].tolist()\n",
    "  lsub_ = lsub[0].tolist()\n",
    "  lpre_ = lpre[0].tolist()\n",
    "  lobj_ = lobj[0].tolist()\n",
    "  lpel_ = lpel[0].tolist()\n",
    "  lket_ = lket[0].tolist()\n",
    "  lcc_ = lcc[0].tolist()\n",
    "  lsc_ = lsc[0].tolist()\n",
    "  lfnom_ = lfnom[0].tolist()\n",
    "  lfnum_ = lfnum[0].tolist()\n",
    "  lfprep_ = lfprep[0].tolist()\n",
    "  lfket_ = lfket[0].tolist()\n",
    "  lfverb_ = lfverb[0].tolist()\n",
    "  lfadje_ = lfadje[0].tolist()\n",
    "  lpewatas_ = lpewatas[0].tolist()\n",
    "  lkonj_ = lkonj[0].tolist()\n",
    "  lsubord_ = lsubord[0].tolist()\n",
    "  lklausa_ = lklausa[0].tolist()\n",
    "\n",
    "  return {\n",
    "      's': ls_,\n",
    "      'a_sub': lsub_,\n",
    "      'b_pre': lpre_,\n",
    "      'c_obj': lobj_,\n",
    "      'd_pel': lpel_,\n",
    "      'e_ket': lket_,\n",
    "      'cc' : lcc_,\n",
    "      'sc' : lsc_,\n",
    "      'fnom': lfnom_,\n",
    "      'fnum': lfnum_,\n",
    "      'fprep': lfprep_,\n",
    "      'fket': lfket_,\n",
    "      'fverb': lfverb_,\n",
    "      'fadje': lfadje_,\n",
    "      'pewatas': lpewatas_,\n",
    "      'konj': lkonj_,\n",
    "      'subord': lsubord_,\n",
    "      'klausa': lklausa_\n",
    "  }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 726,
     "status": "ok",
     "timestamp": 1666250794059,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "qN4YKZf_DItC",
    "outputId": "e9efbced-1b5e-4bd2-d026-63cc7809f05e"
   },
   "outputs": [],
   "source": [
    "#lihat lokasi komponen\n",
    "# arr_loc = []\n",
    "# for i in arr_asli:\n",
    "#   dt = find(i)\n",
    "#   arr_loc.append(dt)\n",
    "\n",
    "# for l in arr_loc:\n",
    "#    print(l)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PEMBUATAN TRIPLET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tahap 1 selesai\n"
     ]
    }
   ],
   "source": [
    "# #mendapatkan type SPOK\n",
    "file1 = open(\"K5.txt\",\"w\")\n",
    "\n",
    "for arr_a in range(len(arr_asli)):\n",
    "    for i in range(len(arr_asli[arr_a])-1):\n",
    "        tree_asli = arr_asli[arr_a][i]\n",
    "        next_tree_asli = arr_asli[arr_a][i + 1]\n",
    "        tree_g = arr_gabungan[arr_a][i]\n",
    "        next_tree_g = arr_gabungan[arr_a][i + 1]\n",
    "\n",
    "        if tree_asli == 's': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'sub': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n') \n",
    "        if tree_asli == 'pre': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'obj': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'pel': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n') \n",
    "        if tree_asli == 'ket': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n') \n",
    "        if tree_asli == 'fnom': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'fprep': \n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'fverb':\n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'pewatas':\n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'klausa':\n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'fnum':\n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "        if tree_asli == 'fadje':\n",
    "            file1.writelines(f'{tree_g} type {tree_asli}\\n')\n",
    "\n",
    "\n",
    "print(\"tahap 1 selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tahap 2 selesai\n"
     ]
    }
   ],
   "source": [
    "# #mendapatkan type dari Tagset\n",
    "\n",
    "for arr_a in range(len(arr_asli)):\n",
    "    for i in range(len(arr_asli[arr_a])-1):\n",
    "        tree_asli = arr_asli[arr_a][i]\n",
    "        next_tree_asli = arr_asli[arr_a][i + 1]\n",
    "        tree_g = arr_gabungan[arr_a][i]\n",
    "        next_tree_g = arr_gabungan[arr_a][i + 1]\n",
    "\n",
    "        if tree_asli == 'nn': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'sc': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'vb': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'nnp': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'jj': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'rb': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'in': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'cd': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'cc': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'pr': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'prp': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'md': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'fw': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'neg': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'dt': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'nnd': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'sym': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'rp': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'OD': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'x': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'wh': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "        if tree_asli == 'uh': \n",
    "            file1.writelines(f'{arr_gabungan[arr_a][i+1]} type {arr_asli[arr_a][i]} \\n')\n",
    "\n",
    "\n",
    "\n",
    "print(\"tahap 2 selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 315,
     "status": "ok",
     "timestamp": 1666254201704,
     "user": {
      "displayName": "Selvia FK",
      "userId": "15526762061037364658"
     },
     "user_tz": -420
    },
    "id": "8eiTkJJmQuZZ",
    "outputId": "0a17e495-4358-4a14-8ed6-620660636105"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tahap 3 selesai\n"
     ]
    }
   ],
   "source": [
    "#pembuatan triplet (versi 3)\n",
    "#konsepnya mundur, s-p-o-pel-k\n",
    "#file1 = open(\"TripletKalimat.txt\",\"w\")\n",
    "\n",
    "for arr_a in range(len(arr_asli)):\n",
    "  #print()\n",
    "  for i in range(len(arr_asli[arr_a])-1):\n",
    "    tree_asli = arr_asli[arr_a][i]\n",
    "    next_tree_asli = arr_asli[arr_a][i + 1]\n",
    "    tree_g = arr_gabungan[arr_a][i]\n",
    "    next_tree_g = arr_gabungan[arr_a][i + 1]\n",
    "  \n",
    "    try:\n",
    "        if (tree_asli == 'sub'and next_tree_asli != 'fnom'):\n",
    "            if (next_tree_asli != 'fnum'):\n",
    "                file1.writelines(f'{tree_g} has{next_tree_asli} {arr_gabungan[arr_a][i+2]}\\n') # sub has nnp\n",
    "        if (tree_asli == 'pre'and next_tree_asli != 'fverb'):\n",
    "            file1.writelines (f'{tree_g} has{next_tree_asli} {arr_gabungan[arr_a][i+2]}\\n') # pre has vb\n",
    "        if (tree_asli == 'obj'and next_tree_asli != 'fnom'):\n",
    "            file1.writelines (f'{tree_g} has{next_tree_asli} {arr_gabungan[arr_a][i+2]}\\n') # obj has nnp\n",
    "        if (tree_asli == 'pel'and next_tree_asli != 'fnom'):\n",
    "            file1.writelines (f'{tree_g} has{next_tree_asli} {arr_gabungan[arr_a][i+2]}\\n') # pel has nnp\n",
    "        if (tree_asli == 'ket' and  arr_asli[arr_a][i + 1] == 'sc'):\n",
    "            file1.writelines (f'{tree_g} hasa{arr_asli[arr_a][i + 1]} {arr_asli[arr_a][i + 2]}\\n') # ket hasSC x\n",
    "            if (arr_asli[arr_a][i + 3] == 'vb' or arr_asli[arr_a][i + 3] == 'nn' or arr_asli[arr_a][i + 3] == 'nnp'):\n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 3]} {arr_asli[arr_a][i + 4]}\\n') # ket hasVB x\n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "            \n",
    "    try:\n",
    "        if  tree_asli == 'fnom':\n",
    "            \n",
    "            if (arr_asli[arr_a][i + 1] != 'fnom' and (arr_asli[arr_a][i + 3] == 'fprep' or arr_asli[arr_a][i + 3] == 'fnom')): \n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]}\\n')#fnom nn fnom\n",
    "            if (arr_asli[arr_a][i + 1] != 'fnom' and arr_asli[arr_a][i + 1] != 'fadje' and arr_asli[arr_a][i + 1] != 'fnum' and arr_asli[arr_a][i + 3] != 'fnom'):  #fnom normal\n",
    "                file1.writelines (f'{tree_g} hasfnom {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfnom {tree_g}b \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}b type {tree_asli} \\n')\n",
    "            if (arr_asli[arr_a][i + 1] != 'fnom' and arr_asli[arr_a][i + 3] == 'cc'):  #fnom cc\n",
    "                file1.writelines (f'{tree_g} hasfnom {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfnom {tree_g}b \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfnom {tree_g}c \\n')\n",
    "                file1.writelines (f'{tree_g}c has{arr_asli[arr_a][i + 5]} {arr_gabungan[arr_a][i + 6]} \\n')\n",
    "                file1.writelines (f'{tree_g}  type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}b type {tree_asli} \\n')   \n",
    "                file1.writelines (f'{tree_g}c type {tree_asli} \\n')\n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "    \n",
    "    try:\n",
    "        if  tree_asli == 'fnum':\n",
    "            if (arr_asli[arr_a][i + 1] != 'fnum' and (arr_asli[arr_a][i + 3] == 'fprep' or \n",
    "                arr_asli[arr_a][i + 3] == 'fnom')): \n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]}\\n')#fprep nn fprep\n",
    "            if (arr_asli[arr_a][i + 1] != 'fnom' and arr_asli[arr_a][i + 1] != 'fnum' and \n",
    "                arr_asli[arr_a][i + 3] != 'fnom'  and arr_asli[arr_a][i + 3] != 'fprep'):  #fnum normal\n",
    "                file1.writelines (f'{tree_g} hasfnum {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfnum {tree_g}b \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}b type {tree_asli} \\n') \n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "    \n",
    "    try:\n",
    "        if  tree_asli == 'fverb': #fverb normal\n",
    "                if arr_asli[arr_a][i + 3] == 'fverb':\n",
    "                    file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]}\\n')\n",
    "                if (arr_asli[arr_a][i + 1] != 'fverb' and arr_asli[arr_a][i + 3] == 'cc'):  #fnom cc\n",
    "                    file1.writelines (f'{tree_g} hasfnom {tree_g}a \\n')\n",
    "                    file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                    file1.writelines (f'{tree_g} hasfnom {tree_g}b \\n')\n",
    "                    file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]}\\n')\n",
    "                    file1.writelines (f'{tree_g} hasfnom {tree_g}c \\n')\n",
    "                    file1.writelines (f'{tree_g}c has{arr_asli[arr_a][i + 5]} {arr_gabungan[arr_a][i + 6]} \\n')\n",
    "                    file1.writelines (f'{tree_g}  type {tree_asli} \\n')\n",
    "                    file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                    file1.writelines (f'{tree_g}b type {tree_asli} \\n')   \n",
    "                    file1.writelines (f'{tree_g}c type {tree_asli} \\n')\n",
    "                else:  \n",
    "                    file1.writelines (f'{tree_g} type {tree_asli}\\n')\n",
    "                    file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                    file1.writelines (f'{tree_g}b type {tree_asli} \\n')\n",
    "                    file1.writelines (f'{tree_g} hasfverb {tree_g}a \\n')\n",
    "                    file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                    file1.writelines (f'{tree_g} hasfverb {tree_g}b \\n')\n",
    "                    file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "                \n",
    "    try:\n",
    "        if  tree_asli == 'fprep':\n",
    "            if (arr_asli[arr_a][i + 1] != 'fprep' and (arr_asli[arr_a][i + 3] == 'fprep' or \n",
    "                arr_asli[arr_a][i + 3] == 'fnom')): \n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')#fprep nn fprep\n",
    "            if (arr_asli[arr_a][i + 1] != 'fprep' and arr_asli[arr_a][i + 1] != 'fnum' and \n",
    "                arr_asli[arr_a][i + 3] != 'fnom'  and arr_asli[arr_a][i + 3] != 'fprep'):  #fadje normal\n",
    "                file1.writelines (f'{tree_g} hasfprep {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfprep {tree_g}b \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}b type {tree_asli} \\n') \n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "    \n",
    "    try:\n",
    "        if  tree_asli == 'fadje':\n",
    "            if (arr_asli[arr_a][i + 1] != 'fadje' and (arr_asli[arr_a][i + 3] == 'fprep' or \n",
    "                arr_asli[arr_a][i + 3] == 'fnom')): \n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')#fadje nn fadje\n",
    "            if (arr_asli[arr_a][i + 1] != 'fadje' and arr_asli[arr_a][i + 1] != 'fnum' and \n",
    "                arr_asli[arr_a][i + 3] != 'fnom'):  #fadje normal\n",
    "                file1.writelines (f'{tree_g} hasfadje {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} hasfadje {tree_g}b  \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}a type {tree_asli} \\n')\n",
    "                file1.writelines (f'{tree_g}b type {tree_asli} \\n') \n",
    "    except:\n",
    "        file1.writelines('\\n')\n",
    "             \n",
    "    try:        \n",
    "        if  tree_asli == 'pewatas':\n",
    "            if (arr_asli[arr_a][i + 3] == 'fnom' or arr_asli[arr_a][i + 3] == 'fprep' or arr_asli[arr_a][i + 3] == 'fverb'): #Pew nn Fnom\n",
    "                file1.writelines (f'{tree_g} has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')          \n",
    "            else:\n",
    "                file1.writelines (f'{tree_g}a type pewatas \\n')\n",
    "                file1.writelines (f'{tree_g}b type pewatas \\n')\n",
    "                file1.writelines (f'{tree_g}c type pewatas \\n')  \n",
    "                file1.writelines (f'{tree_g}a has{arr_asli[arr_a][i + 1]} {arr_gabungan[arr_a][i + 2]} \\n')\n",
    "                file1.writelines (f'{tree_g} haspewatas {tree_g}a \\n')\n",
    "                file1.writelines (f'{tree_g}b has{arr_asli[arr_a][i + 3]} {arr_gabungan[arr_a][i + 4]} \\n')\n",
    "                file1.writelines (f'{tree_g} haspewatas {tree_g}b \\n') \n",
    "                file1.writelines (f'{tree_g}c has{arr_asli[arr_a][i + 5]} {arr_gabungan[arr_a][i + 6]} \\n')\n",
    "                file1.writelines (f'{tree_g} haspewatas {tree_g}c \\n') \n",
    "                file1.writelines (f'{tree_g} type {tree_asli} \\n')        \n",
    "    except:\n",
    "        file1.writelines ('\\n')\n",
    "\n",
    "#file1.close()\n",
    "print(\"tahap 3 selesai\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tahap 4 selesai\n"
     ]
    }
   ],
   "source": [
    "for arr_a in range(len(arr_asli)):\n",
    "  #print(\"\\n\")\n",
    "  for i in range(len(arr_asli[arr_a])-1):\n",
    "    tree_asli = arr_asli[arr_a][i]\n",
    "    next_tree_asli = arr_asli[arr_a][i + 1]\n",
    "    tree_g = arr_gabungan[arr_a][i]\n",
    "    next_tree_g = arr_gabungan[arr_a][i + 1]\n",
    "\n",
    "#mendapatkan susukan kalimat dari SPOK FNOM dll Pew\n",
    "    if tree_asli == 's': \n",
    "        s=tree_g\n",
    "    if tree_asli == 'klausa': \n",
    "        if (tree_asli == 'klausa' and arr_asli[arr_a][i-1]=='s'):\n",
    "            file1.writelines (f'{arr_gabungan[arr_a][0]} hasklausa {tree_g} \\n') \n",
    "            s=tree_g\n",
    "        if (tree_asli == 'klausa' and arr_asli[arr_a][i-2]=='cc'):\n",
    "             file1.writelines (f'{arr_gabungan[arr_a][0]} hasklausa {tree_g} \\n') \n",
    "             file1.writelines (f'{tree_g} hascc {arr_asli[arr_a][i-1]} \\n')\n",
    "             s=tree_g\n",
    "        if (tree_asli == 'klausa' and arr_asli[arr_a][i-2]=='sc'):\n",
    "             file1.writelines (f'{arr_gabungan[arr_a][i-3]} hasklausa {tree_g} \\n') \n",
    "             file1.writelines (f'{arr_gabungan[arr_a][i-3]} hasasc {arr_asli[arr_a][i-1]} \\n')\n",
    "             s=tree_g\n",
    "                \n",
    "    if tree_asli == 'sub': \n",
    "        file1.writelines (f'{s} hasasub {tree_g} \\n')   \n",
    "        tag = (f'{tree_g}')\n",
    "    if tree_asli == 'pre': \n",
    "        file1.writelines (f'{s} hasbpre {tree_g} \\n')\n",
    "        tag =(f'{tree_g}')\n",
    "    if tree_asli == 'obj': \n",
    "        file1.writelines (f'{s} hascobj {tree_g} \\n')\n",
    "        tag =(f'{tree_g}')\n",
    "    if tree_asli == 'pel': \n",
    "        file1.writelines (f'{s} hasdpel {tree_g} \\n')\n",
    "        tag =(f'{tree_g}')\n",
    "    if tree_asli == 'ket': \n",
    "        file1.writelines (f'{s} haseket {tree_g} \\n')\n",
    "        tag =(f'{tree_g}')\n",
    "    if tree_asli == 'pewatas': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g} \\n')\n",
    "        tag=(f'{tree_g}')\n",
    "    if tree_asli == 'fnom': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g} \\n')\n",
    "        tag=(f'{tree_g}')\n",
    "    if tree_asli == 'fnum': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g} \\n')\n",
    "        tag=(f'{tree_g}')     \n",
    "    if tree_asli == 'fverb': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g}\\n')\n",
    "        tag=(f'{tree_g}')         \n",
    "    if tree_asli == 'fprep': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g} \\n')\n",
    "        tag=(f'{tree_g}')          \n",
    "    if tree_asli == 'fadje': \n",
    "        file1.writelines (f'{tag} hasznext {tree_g} \\n')\n",
    "        tag=(f'{tree_g}')\n",
    "#         if (arr_asli[arr_a][i+1] != 'fadje' and (arr_asli[arr_a][i+1] == 'fnom' or arr_asli[arr_a][i+1] == 'fnum'):\n",
    "#             file1.writelines (f'{tag} has{arr_asli[arr_a][i+1]} {arr_gabungan[arr_a][i]} \\n') \n",
    "\n",
    "        \n",
    "file1.close()\n",
    "print(\"tahap 4 selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE:\n",
    "# LOAD SELURUH TRIPLET YANG DIHASILKAN AGAR MASUK KE OWL, CARA LOAD ADA DI BAWAH\n",
    "# PADA BAGIAN ATAS INI, HILANGKAN BARIS YG TIDAK BERUPA TRIPLET (FNOM1 DAN KET1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRIPLET TO OWL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def bacaTriplet(namaFile):\n",
    "    lines = []\n",
    "    with open(namaFile,'r+') as f:\n",
    "        line=f.read().splitlines()\n",
    "        lines.append(line)\n",
    "    lines = np.array(lines)\n",
    "    subjek = []\n",
    "    for i in range(lines.shape[1]):\n",
    "        a = lines[0,i].split(\" \")\n",
    "        subjek.append(a)\n",
    "    return subjek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet = bacaTriplet('K5.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from owlready2 import *\n",
    "onto = get_ontology(\"Eksperimen.owl\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Menambahkan Instance\n",
    "\n",
    "from owlready2 import *\n",
    "onto = get_ontology(\"Eksperimen.owl\").load()\n",
    "\n",
    "for i in triplet:\n",
    "    if(i[1] == 'type' and i[2] == 's'):\n",
    "        onto.Kalimat(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'klausa'):\n",
    "        onto.Klausa(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'sub'):\n",
    "        onto.Subjek(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'pre'):\n",
    "        onto.Predikat(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'obj'):\n",
    "        onto.Objek(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'pel'):\n",
    "        onto.Pelengkap(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'ket'):\n",
    "        onto.Keterangan(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'pewatas'):\n",
    "        onto.Pewatas(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'cc'):\n",
    "        onto.CC(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'cd'):\n",
    "        onto.CD(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'dt'):\n",
    "        onto.DT(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fadje'):\n",
    "        onto.FAdje(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fadv'):\n",
    "        onto.FAdv(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fnom'):\n",
    "        onto.FNom(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fnum'):\n",
    "        onto.FNum(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fprep'):\n",
    "        onto.FPrep(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fverb'):\n",
    "        onto.FVerb(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'fw'):\n",
    "        onto.FW(i[0])    \n",
    "    if(i[1] == 'type' and i[2] == 'in'):\n",
    "        onto.IN(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'jj'):\n",
    "        onto.JJ(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'md'):\n",
    "        onto.MD(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'neg'):\n",
    "        onto.NEG(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'nn'):\n",
    "        onto.NN(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'nnd'):\n",
    "        onto.NND(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'nnp'):\n",
    "        onto.NNP(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'od'):\n",
    "        onto.OD(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'pr'):\n",
    "        onto.PR(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'prp'):\n",
    "        onto.PRP(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'rb'):\n",
    "        onto.RB(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'rp'):\n",
    "        onto.RP(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'sc'):\n",
    "        onto.SC(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'sym'):\n",
    "        onto.SYM(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'uh'):\n",
    "        onto.UH(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'vb'):\n",
    "        onto.VB(i[0])\n",
    "    if(i[1] == 'type' and i[2] == 'wh'):\n",
    "        onto.WH(i[0])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menyimpan owl\n",
    "onto.save(\"Eksperimen.owl\", format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Penambahan Relasi selesai\n"
     ]
    }
   ],
   "source": [
    "#https://pythonhosted.org/Owlready/properties.html\n",
    "#Menambahkan Relasi\n",
    "file2 = open(\"K6.txt\",\"w\")\n",
    "\n",
    "for i in triplet:   \n",
    "    if(i[1] == 'hasrb'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasRB.append(onto.RB(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasrp'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasRP.append(onto.RP(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasasc'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasaSC.append(onto.SC(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hassym'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasSYM.append(onto.SYM(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasuh'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasUH.append(onto.UH(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasvb'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasVB.append(onto.VB(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'haswh'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasWH.append(onto.WH(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasmd'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasMD.append(onto.MD(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hascc'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasCC.append(onto.CC(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hascd'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasCD.append(onto.CD(\"'+i[2]+'\"))\\n') \n",
    "    if(i[1] == 'hasdt'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasDT.append(onto.DT(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasfw'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFW.append(onto.FW(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasin'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasIN.append(onto.IN(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasjj'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasJJ.append(onto.JJ(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasnn'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasNN.append(onto.NN(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasnnd'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasNND.append(onto.NND(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasnnp'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasNNP.append(onto.NNP(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasneg'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasNEG.append(onto.NEG(\"'+i[2]+'\"))\\n') \n",
    "    if(i[1] == 'hasod'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasOD.append(onto.OD(\"'+i[2]+'\"))\\n') \n",
    "    if(i[1] == 'haspr'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasPR.append(onto.PR(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasprp'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasPRP.append(onto.PRP(\"'+i[2]+'\"))\\n')\n",
    "        \n",
    "    if(i[1] == 'hasnext'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasNext.append(onto.S(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasprev'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasPrev.append(onto.Prev(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'haspart'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasPart.append(onto.Part(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasznext'):\n",
    "        if ('pewatas' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.Pewatas(\"'+i[2]+'\"))\\n')\n",
    "        if ('fadje' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.FAdje(\"'+i[2]+'\"))\\n')\n",
    "        if ('fnom' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.FNom(\"'+i[2]+'\"))\\n')\n",
    "        if ('fnum' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.FNum(\"'+i[2]+'\"))\\n')\n",
    "        if ('fprep' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.FPrep(\"'+i[2]+'\"))\\n')\n",
    "        if ('fverb' in i[2]):\n",
    "            file2.writelines ('onto.'+i[0]+'.hasZnext.append(onto.FVerb(\"'+i[2]+'\"))\\n')\n",
    "        \n",
    "    if(i[1] == 'hasfadje'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFadje.append(onto.FAdje(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasfnom'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFnom.append(onto.FNom(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasfnum'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFnum.append(onto.FNum(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasfprep'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFprep.append(onto.FPrep(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasfverb'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasFverb.append(onto.FVerb(\"'+i[2]+'\"))\\n')\n",
    "    \n",
    "    if(i[1] == 'hasklausa'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasKlausa.append(onto.Klausa(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasasub'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasaSub.append(onto.Subjek(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasbpre'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasbPre.append(onto.Predikat(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hascobj'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hascObj.append(onto.Objek(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'hasdpel'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasdPel.append(onto.Pelengkap(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'haseket'):\n",
    "        file2.writelines ('onto.'+i[0]+'.haseKet.append(onto.Keterangan(\"'+i[2]+'\"))\\n')\n",
    "    if(i[1] == 'haspewatas'):\n",
    "        file2.writelines ('onto.'+i[0]+'.hasPewatas.append(onto.Pewatas(\"'+i[2]+'\"))\\n')\n",
    "\n",
    "\n",
    "file2.close()\n",
    "print (\"Penambahan Relasi selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MEMASUKKAN RELASI [S]-->[SUB] or [S]-->[PRE]\n",
    "from owlready2 import *\n",
    "onto = get_ontology(\"Eksperimen.owl\").load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Insert data from TripletRelasi.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "onto.sub1.hasNNP.append(onto.NNP(\"mollusca\"))\n",
    "onto.pre1.hasVB.append(onto.VB(\"adalah\"))\n",
    "onto.obj1.hasNN.append(onto.NN(\"hewan\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#menyimpan owl\n",
    "onto.save(\"Eksperimen.owl\", format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tambah hasNext dan seeAlso\n",
    "from owlready2 import *\n",
    "onto = get_ontology(\"Eksperimen.owl\").load()\n",
    "\n",
    "onto.Mollusca.seeAlso.append(onto.Kalimat(\"s1\"))\n",
    "onto.s2.hasNext.append(onto.Kalimat(\"sV3\"))\n",
    "\n",
    "onto.save(\"Eksperimen.owl\", format = \"rdfxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
